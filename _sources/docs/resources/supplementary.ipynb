{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8db50243",
   "metadata": {},
   "source": [
    "# Supplementary Material\n",
    "\n",
    "Here, we summarize all the links to our repositories and results. Each repository contains an example of how to execute the contained source code.\n",
    "\n",
    "## Full Pipeline\n",
    "Our full pipeline presented and detailed in Chapter 5 with its requirements and examples of how to run are available in [[Full Pipeline link]](https://github.com/covid-vr/covid-vr-docker).\n",
    "\n",
    "## Independent Repositories\n",
    "In this Section we detail the main components of our Full Pipeline which can be used independently. Each repository contains an example of how to execute the code.\n",
    "\n",
    "### Lung segmentation\n",
    "Required packages and minimum versions. For complete detail see at require-\n",
    "ments.txt in our adapted P-HNN version:\n",
    "- Python 3.6\n",
    "- Pytorch 1.3\n",
    "- Cudatoolkit 10.1\n",
    "- Anaconda\n",
    "\n",
    "Link to repositories:\n",
    "- Original P-HNN repository [[link]](https://adampharrison.gitlab.io/p-hnn/).\n",
    "- Our adapted P-HNN version [[link]](https://github.com/covid-vr/p-hnn-lung-segmentation).\n",
    "- Model Weights [[link]](https://drive.google.com/file/d/1l6yLFScULNw-oVoark0KZ-wnDFX8zwrN/view?usp=sharing).\n",
    "\n",
    "### Visualization Repositories\n",
    "Minimum required libraries:\n",
    "- CMake 3.17\n",
    "- QT 5.12\n",
    "- MITK [[link]](https://github.com/MITK/MITK)\n",
    "- ffmpeg (For video-generator repository)\n",
    "\n",
    "Link to repositories:\n",
    "- Repository to capture view images [[link]](https://github.com/covid-vr/camera-shots-generator).\n",
    "- Repository for video generation from CT Image [[link]](https://github.com/covid-vr/video-generator).\n",
    "\n",
    "Both repositories need as input an image in NIfTI format and a XML for the transfer functions, samples of both were added to each repository. We highly recommend using a Desktop environment (with UI); however, could be used in a server environment like our Full Pipeline, using VGLRUN command along with the steps described in Full Pipeline link.\n",
    "\n",
    "### COVID-VR Proposed Network\n",
    "Required minimum versions (the complete requirements are in the repository link):\n",
    "- Python 3.6\n",
    "- TensorFlow 2.0\n",
    "Link to repositories:\n",
    "- Repository for train and validation: [[link]](https://github.com/covid-vr/covid-vr-network).\n",
    "- Model weights (For the two views) [[link]](https://drive.google.com/drive/folders/1OXTliIhm7yGuBDIL7qZhQrjCoaxmGx0l).\n",
    "\n",
    "### Additional Resources\n",
    "- Repository for get metrics (accuracy, precision, f1-measure, etc) and generate graphics used in this work [[link]](https://github.com/covid-vr/model-evaluation-metrics).\n",
    "- Repository to generate Grad-CAM visualizations [[link]](https://github.com/covid-vr/covid-vr-grad-cam)."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "source_map": [
   10
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}